---
layout: post
comments: True
title: VLCTesting Valencia 2016
tags: talks 
eye_catch: ""
---

Parece mentira que haya pasado un año...

![](http://emerrefe.github.io/qa-blog/images/vlctesting2016.png)

La verdad este VLCTesting me ha parecido muy bueno. Es la segunda vez que asisto y quién me iba a decir a mi que 
este año estaría viviendo en Valencia :)

Como la otra vez, quiero recoger un resumen de las ponencias y los seminarios por si esta información os parece interesante.

# En relación a las ponencias:

## Software testing… ¡Hay que echarle valor!
por **Maximiliano Mannise**

Siempre abre camino con tono divertido y esta vez con las distintas acepciones para la palabra valor en testing:
Valor como valentía y coraje para poder llevar un proyecto adelante.
Valor como satisfacer una necesidad del usuario.
Valor que las personas aportan en todo el proceso, nuestras skills, no sólo por los testers sino por todos y el trabajo en equipo.
Además nos comentó que aunque sabemos que nuestra misión principal es encontrar esos bugs, eso no es entregar valor, 
debemos aportar mucho más, dar más información para así poder defender la calidad del producto.
Igualmente debemos dar visibilidad al tiempo que se debe dedicar al testing en los proyectos.

Esta ponencia me hizo recordar [este vídeo](https://www.youtube.com/watch?v=8TX6rzz60xQ) de James Bach sobre la aplicación del pensamiento crítico.

También hizo hincapié en el análisis de la causa raíz y los 5 porqués que facilita averiguar la causa de un determinado problema.
Si no la conocéis podéis echar un ojo a [este post](http://www.pdcahome.com/7642/analisis-de-causa-raiz-metodologia-para-investigar-y-resolver-incidencias).
(aunque no debemos olvidar que esto nos puede llevar equivocadamente a encontrar una única causa y normalmente la realidad incluye más
variables a la ecuación y por tanto más causas).

## Devops Mythbusters
por **Salvador Folgado y Jordi Borja**

Comentaron los mitos que han detectado a la hora de implantar la figura del DevOps en las empresas.
Anteriormente al ciclo de conferencias nos enviaron un correo con una encuesta sobre esto y aquí los han expuesto y comentado.

En resumen es recordar que quienes trabajan en operaciones lo hace para dar información y 
preparar la infraestructura según la demanda y dar valor al negocio.


## ¿Cómo hemos potenciado nuestro desarrollo ágil con testing BDD?
por **Jorge López Mateo**

<center><blockquote class="twitter-tweet" data-lang="es"><p lang="es" dir="ltr">Jorge López nos explica en <a href="https://twitter.com/hashtag/VLCTESTING16?src=hash">#VLCTESTING16</a> el concepto de BDD y un caso de éxito <a href="https://t.co/v3qtmq46xl">pic.twitter.com/v3qtmq46xl</a></p>&mdash; Juan Lopez (@JuanLopezVi) <a href="https://twitter.com/JuanLopezVi/status/796287023640440832">9 de noviembre de 2016</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></center>

Ya que el cerebro humano no entiende las abstracciones de primera mano, cuantos más ejemplos tenemos de algo,
mejor entendemos los conceptos. Por ello en BDD se hace un boceto de las pruebas en lenguaje natural 
(precondiciones, evento y postcondiciones), se escriben ejemplos y después se hacen ejecutables.

Es muy buena excusa para juntar al analista, el tester y el desarrollador para crear esos ejemplos concretos 
que sirven de referencia para los planes de pruebas y para aportar el valor que el usuario final demanda.

Contaron que en su empres han mejorado con BDD la mantenibilidad de los tests unitarios. Con ello se han dado cuenta 
de que se suavizan las fases por las que pasa el producto y se fomenta el mundo agile.

Además nombró frameworks como [cucumber](https://cucumber.io) que ayudan a facilitar esta implantación de BDD.


## Mejorando testesrs, de 0 a 100 
por **Tomislav Delalic y Jokin Aspiazu**

<center><blockquote class="twitter-tweet" data-lang="es"><p lang="es" dir="ltr">Formación en test ... solo se necesita tiempo y dinero Tomi y Jok en <a href="https://twitter.com/hashtag/VLCTesting16?src=hash">#VLCTesting16</a> <a href="https://t.co/QlBmc5uVxF">pic.twitter.com/QlBmc5uVxF</a></p>&mdash; Maximiliano Mannise (@mmannise) <a href="https://twitter.com/mmannise/status/796318340209852416">9 de noviembre de 2016</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></center>

Nos contaron su propio aprendizaje y crecimiento como testers.  Una de sus reflexiones es que resulta
difícil encontrar testers y cuando los encuentras, se hace difícil también reclutarlos.
La clave está en dar oportunidad a la gente que empieza desde 0 e invertir en mejorarlos y aportarles. Hace falta tiempo y 
dinero. ¡Hay que invertir en formación!
Según la compañía, se puede organizar más o menos a los testers, con planes a corto, medio y largo plazo. Por ejemplo, emplear 5 semanas 
de formación para asentar las bases del testing, principios agile y técnicas de automatización. Además permitir al candidato estudiar
algún curso enfocado al testeo.
Otro punto muy importante es volcarse en eventos que invitan a aprender y hacer comunidad.

## Grande, pequeño, ancho y largo. ¡Vamos  a poner a prueba la responsiveness!
por **Eduardo Luna**

Tuvo que estudiar cómo plantear una estrategia para tener un diseño web responsive. Además qué recursos emplear 
para defender por qué no sacar a producción un producto que no consideraba de calidad debido a no ser responsive.
¡El diseño web debe ser adaptativo!
Hay que considerar temas como el público al que va dirigido el producto, mirar todas las plataformas en que será utilizado, 
cuales son las versiones más utilizadas, navegadores de más  uso, la conectividad con la que cuentan esos dispositivos,  
el método de entrada de datos, las resoluciones y orientación de las pantallas, el ámbito geográfico
de los usuarios...
Destacó también la importancia de realizar bocetos desde el primer momento que, de un simple vistazo, se pueda observar
cuál es la intención del producto.
Finalmente ver cómo será el test plan, que tenga un reporting muy visual y que nos de la visión general muy rápida.
Es imposible testear todo en todos los dispositivos. Utilizar frameworks como BrowserStack, Galen etc es una gran idea
pero si se puede utilizar el movil físico mejor.
Nunca hay que olvidar las 5 condiciones de test: navegación, rendimiento, condiciones del usuario, 
cobertura de plataforma y testing visual.

## Amenazas en el internet de las cosas
por **Josep Albors**

<center><blockquote class="twitter-tweet" data-lang="es"><p lang="es" dir="ltr"><a href="https://twitter.com/JosepAlbors">@JosepAlbors</a> &quot;escalofriante&quot; es la palabra que tengo en mente tras escucharte <a href="https://twitter.com/hashtag/VLCTesting16?src=hash">#VLCTesting16</a> la seguridad en el IoT... Muy buena!!</p>&mdash; emerrefe (@emerrefe) <a href="https://twitter.com/emerrefe/status/796328907431706624">9 de noviembre de 2016</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></center>

Divertido a la par que escalofriante.
El internet de las cosas tiene ahora el poder y debemos ser conscientes de que no esta securizado. 
Prueba de ello es el reciente ataque DDoS del que hemos sido testigos y que podemos 
leer en [esta noticia](http://www.xataka.com/servicios/los-responsables-del-ddos-a-dyn-usaron-camaras-ip-y-dvrs-para-tumbar-medio-internet).
A partir de ahora, simplemente desconfiad de vuestra cafetera y vuestra nevera. Ahí queda.


## Cómo probamos SW en idealista
por **Raúl Hernández**

Nos comentó que tienen equipos independientes de las distintas disciplinas y dan soporte en todos los proyectos 
donde haga falta. La calidad es responsabilidad de todos.
Ponen el foco en el usuario final (sobre todo realizando pruebas exploratorias y de aceptación).
Además ponen mucho énfasis en la automatización de las pruebas sin olvidar nunca las manuales. Siempre tendremos que probar 
manualmente para que sea útil el feedback. Su proporción de pruebas es básicamente 50/50 (manuales vs automatizadas).
También, en cuanto a detalles técnicos, nos informó de que en los tests automáticos utilizan PageObject (si queréis más detalles
sobre este patrón podéis pasar por [uno de mis antiguos posts](https://emerrefe.github.io/qa-blog/page-object-pattern) ).

## La evolución del QA. Del mono al QA
por **Jorge Barroso**

Nos propuso un inteligente símil entre la evolución humana y el QA.
De esta manera nos proporcionó un resumen para poder ver en qué estado de la evolución nos encontramos
con determinado equipo y proyecto y ver hacia adonde avanzar.

## El software escondido
por **Francesc Pastor**

Relacionado con el testing en sistemas embebidos, esos grandes desconocidos.
Este software también necesitamos testearlo. Para llevar a cabo esto, se crea una interfaz y así se consigue
captar la información del sistema dejando todo preparado para el posterior testeo. Por ejemplo AUTOSAR para automóviles,
nos proporciona una abstracción del microprocesador o hardware, así tenemos la funcionalidad que quiere el cliente lista
para probar.
Tampoco hay que dejar de lado la seguridad funcional (que tiene en cuenta la oportunidad, el impacto legal, la independencia y la aplicación hw y sw).
Y algo súper importante es que centran su atención en los posibles fallos que impliquen un riesgo para las personas
(dandoles prioridad frente a los posibles fallos del sistema).


# En relación a los seminarios:


